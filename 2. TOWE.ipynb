{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"0b402fc1fdef4e4c86ee114e162f1162":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_680950897a6045b3ad490d339d9fbf5a","IPY_MODEL_ce3d7f9701344e64842d7e86acd81418","IPY_MODEL_a121bcc98f914e7ca817059e18c6181a"],"layout":"IPY_MODEL_d454399a61ca4ecf8bade7c0399aab95"}},"680950897a6045b3ad490d339d9fbf5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52689ad907ce40c38eb0ef97def39839","placeholder":"​","style":"IPY_MODEL_d2f25c8c29b74174832cf0bb1c55582d","value":"100%"}},"ce3d7f9701344e64842d7e86acd81418":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24fda31e5a214db49127c9df1c97aef2","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9ee668013fc4638876f96bb2509e1c9","value":2}},"a121bcc98f914e7ca817059e18c6181a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_178bcf7f8d1744c39a8a908771e4b66d","placeholder":"​","style":"IPY_MODEL_e2ecad26a512490cae1f4b1dc2578861","value":" 2/2 [00:00&lt;00:00,  6.28ba/s]"}},"d454399a61ca4ecf8bade7c0399aab95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52689ad907ce40c38eb0ef97def39839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2f25c8c29b74174832cf0bb1c55582d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24fda31e5a214db49127c9df1c97aef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9ee668013fc4638876f96bb2509e1c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"178bcf7f8d1744c39a8a908771e4b66d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2ecad26a512490cae1f4b1dc2578861":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"740736efbab34b5f9dee0a5bfe91c077":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f11df1de6bfd4c5dbad8477792e16733","IPY_MODEL_5045954242d842c9ab867c5697dfec4a","IPY_MODEL_10609b7f781141238216fcf64ec06d93"],"layout":"IPY_MODEL_e839f710ec2e4a89a6b355c6dbbc5478"}},"f11df1de6bfd4c5dbad8477792e16733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5e1505c2b8f4020a2151a0094462725","placeholder":"​","style":"IPY_MODEL_155b8ba31e4346f8acada343163f170e","value":"100%"}},"5045954242d842c9ab867c5697dfec4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa5748f4bf34d67bbc46d3fd045070a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7958e577bc094a41b615922d48469c36","value":1}},"10609b7f781141238216fcf64ec06d93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b26df9d3a8f440ebc7de04f63dfddb2","placeholder":"​","style":"IPY_MODEL_ff517a15bc7043ed8e0f1ce433f68e7d","value":" 1/1 [00:00&lt;00:00, 11.18ba/s]"}},"e839f710ec2e4a89a6b355c6dbbc5478":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5e1505c2b8f4020a2151a0094462725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"155b8ba31e4346f8acada343163f170e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aa5748f4bf34d67bbc46d3fd045070a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7958e577bc094a41b615922d48469c36":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b26df9d3a8f440ebc7de04f63dfddb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff517a15bc7043ed8e0f1ce433f68e7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8030147aaada4cb688eddd7eadeaa352":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f031f9709c94ad3a3190c24a04b48de","IPY_MODEL_d7b9c40e673e4ac99d8624066410b4fc","IPY_MODEL_a772a4f338f7454a8f228d8641e2479f"],"layout":"IPY_MODEL_dcbe36f672734b66ab7ecec68e30dd33"}},"7f031f9709c94ad3a3190c24a04b48de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d9236c631604726993957cacb5ecf51","placeholder":"​","style":"IPY_MODEL_aa027595e29746b0be444f164907c999","value":"100%"}},"d7b9c40e673e4ac99d8624066410b4fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14dcff6c33474e0bb23b4def5aba4a67","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b5ac2cd8434478d9fa1f68169871aa7","value":1}},"a772a4f338f7454a8f228d8641e2479f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea304110634d4573976e11246352b6d0","placeholder":"​","style":"IPY_MODEL_2cdd82dfb3f7438194ddb78f37f299c7","value":" 1/1 [00:00&lt;00:00, 31.69ba/s]"}},"dcbe36f672734b66ab7ecec68e30dd33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d9236c631604726993957cacb5ecf51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa027595e29746b0be444f164907c999":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14dcff6c33474e0bb23b4def5aba4a67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b5ac2cd8434478d9fa1f68169871aa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea304110634d4573976e11246352b6d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cdd82dfb3f7438194ddb78f37f299c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Process\n","\n","Convert the Apect Term Extraction (ATE) sub problem as a sequence tagging problem."],"metadata":{"id":"caW4G4h8vWYr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QnzAWk-AoT7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669435036874,"user_tz":420,"elapsed":18174,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"9d7aeb05-ac2c-4aca-8360-4227299e576a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["try:\n","    import google.colab\n","    IN_COLAB = True\n","except:\n","    IN_COLAB = False"],"metadata":{"id":"MFGNsRmjoh0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if IN_COLAB:\n","    import nltk\n","    nltk.download('punkt')\n","    !pip install transformers\n","    !pip install datasets\n","    !pip install seqeval\n","    !pip install evaluate\n","    !pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KgXqtPCwojgK","executionInfo":{"status":"ok","timestamp":1669435077859,"user_tz":420,"elapsed":34475,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"e59c4bf5-46d2-4753-ee51-38cb0043c671"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 13.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 71.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 59.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 15.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 95.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 85.4 MB/s \n","\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 68.0 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=e9a0cc45ba76074cd1a82d364cd02496cbd4c2feb7f11b9e14baf34dae7b9ed9\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting evaluate\n","  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n","\u001b[K     |████████████████████████████████| 72 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.13.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.3.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from evaluate) (3.1.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from evaluate) (21.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.23.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.7.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.64.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.11.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2022.11.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.1.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->evaluate) (3.10.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n","Installing collected packages: evaluate\n","Successfully installed evaluate-0.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 14.4 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","from tqdm.notebook import tqdm\n","from logging import raiseExceptions\n","\n","from nltk.tokenize import word_tokenize\n","\n","from datasets import Dataset, DatasetDict, load_metric, Features, ClassLabel\n","from transformers import DataCollatorForTokenClassification\n","from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer"],"metadata":{"id":"RkEdUZNLomq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if IN_COLAB:\n","    root_path = '/content/drive/MyDrive/Knowledge/MSIT/IFT598 - NLP/Final Project'\n","else:\n","    root_path = os.getcwd()"],"metadata":{"id":"I37SzBb4v4cN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the data to bring it to the required format as required for sequence tagging problem.\n","\n","data_path = os.path.join(root_path, 'data')"],"metadata":{"id":"26qXwKYowI0v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lapt14_train = pd.read_csv(os.path.join(data_path, 'towe', '14lap_train.tsv'), sep='\\t')\n","lapt14_test = pd.read_csv(os.path.join(data_path, 'towe', '14lap_test.tsv'), sep='\\t')"],"metadata":{"id":"uQPY6FFES-dH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(dataframe):\n","    dataframe['sentence_tokens'] = dataframe['sentence'].apply(lambda x: word_tokenize(x))\n","\n","    dataframe['target_tags_'] = dataframe['target_tags'].apply(lambda x: [i.split('\\\\')[-1] for i in x.split()])\n","    dataframe['target_tags_'] = dataframe['target_tags_'].apply(lambda x: [idx for idx, i in enumerate(x) if i in ['B', 'I']])\n","    dataframe['aspects'] = dataframe[['sentence_tokens', 'target_tags_']].apply(lambda x: ' '.join([x[0][i] for i in x[1]]), axis=1)\n","\n","    opinion_label_map = {'O':0, 'B':1, 'I':1}\n","\n","    dataframe['tags'] = dataframe['opinion_words_tags'].apply(lambda x: [opinion_label_map[i.split('\\\\')[-1]] for i in x.split()])\n","    dataframe['opinion_words_tags_'] = dataframe['tags'].apply(lambda x: [idx for idx, i in enumerate(x) if i in [1]])\n","    dataframe['opinion_words'] = dataframe[['sentence_tokens', 'opinion_words_tags_']].apply(lambda x: ' '.join([x[0][i] for i in x[1]]), axis=1)\n","\n","    # Encode the target aspect word into the sentence\n","    dataframe['sentence_token_len'] = dataframe['sentence'].apply(lambda x: len(word_tokenize(x)))\n","    dataframe['text'] = dataframe[['sentence', 'aspects']].apply(lambda x: x[0] + f\" The aspect identified is: {x[1]}\", axis=1)\n","    dataframe['tokens'] = dataframe['text'].apply(lambda x: word_tokenize(x))\n","    dataframe['text_token_len'] = dataframe['tokens'].apply(lambda x: len(x))\n","\n","    # Add additional 0 labels to opinion_words_tags_label to match the length of input text tokens\n","    dataframe['additional_tags_len'] = dataframe['text_token_len'] - dataframe['sentence_token_len']\n","    dataframe['tags'] = dataframe[['tags', 'additional_tags_len']].apply(lambda x: x[0] + [0]*x[1], axis=1)\n","    dataframe.drop(['additional_tags_len', 'text_token_len', 'sentence_token_len'], axis=1, inplace=True)\n","\n","    # Removing files with incorrect tags and tokens length mismatch\n","    dataframe = dataframe[dataframe[['tags', 'tokens']].apply(lambda x: len(x[0])==len(x[1]), axis=1)]\n","    return dataframe"],"metadata":{"id":"WtvqnhZmUGy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lapt14_train = preprocess(lapt14_train)\n","lapt14_test = preprocess(lapt14_test)"],"metadata":{"id":"wXj7_SIvCEHY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lapt14_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"DGqhc8iP3Ees","executionInfo":{"status":"ok","timestamp":1669435249007,"user_tz":420,"elapsed":5,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"864415b4-6855-409d-a875-6072ef878221"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   s_id                                           sentence  \\\n","0  2339  I charge it at night and skip taking the cord ...   \n","1  2005  it is of high quality , has a killer GUI , is ...   \n","2  2005  it is of high quality , has a killer GUI , is ...   \n","3  2005  it is of high quality , has a killer GUI , is ...   \n","4  2005  it is of high quality , has a killer GUI , is ...   \n","\n","                                         target_tags  \\\n","0  I\\O charge\\O it\\O at\\O night\\O and\\O skip\\O ta...   \n","1  it\\O is\\O of\\O high\\O quality\\B ,\\O has\\O a\\O ...   \n","2  it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...   \n","3  it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...   \n","4  it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...   \n","\n","                                  opinion_words_tags  \\\n","0  I\\O charge\\O it\\O at\\O night\\O and\\O skip\\O ta...   \n","1  it\\O is\\O of\\O high\\B quality\\O ,\\O has\\O a\\O ...   \n","2  it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...   \n","3  it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...   \n","4  it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...   \n","\n","                                     sentence_tokens target_tags_  \\\n","0  [I, charge, it, at, night, and, skip, taking, ...     [16, 17]   \n","1  [it, is, of, high, quality, ,, has, a, killer,...          [4]   \n","2  [it, is, of, high, quality, ,, has, a, killer,...          [9]   \n","3  [it, is, of, high, quality, ,, has, a, killer,...         [26]   \n","4  [it, is, of, high, quality, ,, has, a, killer,...         [31]   \n","\n","        aspects                                               tags  \\\n","0  battery life  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","1       quality  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","2           GUI  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n","3  applications  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","4           use  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","\n","  opinion_words_tags_ opinion_words  \\\n","0                [15]          good   \n","1                 [3]          high   \n","2                 [8]        killer   \n","3                [25]          good   \n","4                [29]          easy   \n","\n","                                                text  \\\n","0  I charge it at night and skip taking the cord ...   \n","1  it is of high quality , has a killer GUI , is ...   \n","2  it is of high quality , has a killer GUI , is ...   \n","3  it is of high quality , has a killer GUI , is ...   \n","4  it is of high quality , has a killer GUI , is ...   \n","\n","                                              tokens  \n","0  [I, charge, it, at, night, and, skip, taking, ...  \n","1  [it, is, of, high, quality, ,, has, a, killer,...  \n","2  [it, is, of, high, quality, ,, has, a, killer,...  \n","3  [it, is, of, high, quality, ,, has, a, killer,...  \n","4  [it, is, of, high, quality, ,, has, a, killer,...  "],"text/html":["\n","  <div id=\"df-d579144f-747b-4ec5-835a-d7e3433d332d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>s_id</th>\n","      <th>sentence</th>\n","      <th>target_tags</th>\n","      <th>opinion_words_tags</th>\n","      <th>sentence_tokens</th>\n","      <th>target_tags_</th>\n","      <th>aspects</th>\n","      <th>tags</th>\n","      <th>opinion_words_tags_</th>\n","      <th>opinion_words</th>\n","      <th>text</th>\n","      <th>tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2339</td>\n","      <td>I charge it at night and skip taking the cord ...</td>\n","      <td>I\\O charge\\O it\\O at\\O night\\O and\\O skip\\O ta...</td>\n","      <td>I\\O charge\\O it\\O at\\O night\\O and\\O skip\\O ta...</td>\n","      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n","      <td>[16, 17]</td>\n","      <td>battery life</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[15]</td>\n","      <td>good</td>\n","      <td>I charge it at night and skip taking the cord ...</td>\n","      <td>[I, charge, it, at, night, and, skip, taking, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2005</td>\n","      <td>it is of high quality , has a killer GUI , is ...</td>\n","      <td>it\\O is\\O of\\O high\\O quality\\B ,\\O has\\O a\\O ...</td>\n","      <td>it\\O is\\O of\\O high\\B quality\\O ,\\O has\\O a\\O ...</td>\n","      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n","      <td>[4]</td>\n","      <td>quality</td>\n","      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[3]</td>\n","      <td>high</td>\n","      <td>it is of high quality , has a killer GUI , is ...</td>\n","      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2005</td>\n","      <td>it is of high quality , has a killer GUI , is ...</td>\n","      <td>it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...</td>\n","      <td>it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...</td>\n","      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n","      <td>[9]</td>\n","      <td>GUI</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[8]</td>\n","      <td>killer</td>\n","      <td>it is of high quality , has a killer GUI , is ...</td>\n","      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2005</td>\n","      <td>it is of high quality , has a killer GUI , is ...</td>\n","      <td>it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...</td>\n","      <td>it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...</td>\n","      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n","      <td>[26]</td>\n","      <td>applications</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[25]</td>\n","      <td>good</td>\n","      <td>it is of high quality , has a killer GUI , is ...</td>\n","      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2005</td>\n","      <td>it is of high quality , has a killer GUI , is ...</td>\n","      <td>it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...</td>\n","      <td>it\\O is\\O of\\O high\\O quality\\O ,\\O has\\O a\\O ...</td>\n","      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n","      <td>[31]</td>\n","      <td>use</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[29]</td>\n","      <td>easy</td>\n","      <td>it is of high quality , has a killer GUI , is ...</td>\n","      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d579144f-747b-4ec5-835a-d7e3433d332d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d579144f-747b-4ec5-835a-d7e3433d332d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d579144f-747b-4ec5-835a-d7e3433d332d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# lapt14_train['opinion_words_tags_']"],"metadata":{"id":"Ct-8EAE3GHze"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create huggingface dataset\n","towedata = DatasetDict({'train': Dataset.from_pandas(lapt14_train[['tokens', 'tags']]), 'test': Dataset.from_pandas(lapt14_test[['tokens', 'tags']])})"],"metadata":{"id":"pIVcRardEWKW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, label in enumerate(examples[f\"tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:  # Set the special tokens to -100.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n","                label_ids.append(label[word_idx])\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"],"metadata":{"id":"wIDHME-jvL_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\")"],"metadata":{"id":"xRLLV0EdqWN3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Align dataset tags and tokens to handle subwords\n","tokenized_towedata = towedata.map(tokenize_and_align_labels, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["0b402fc1fdef4e4c86ee114e162f1162","680950897a6045b3ad490d339d9fbf5a","ce3d7f9701344e64842d7e86acd81418","a121bcc98f914e7ca817059e18c6181a","d454399a61ca4ecf8bade7c0399aab95","52689ad907ce40c38eb0ef97def39839","d2f25c8c29b74174832cf0bb1c55582d","24fda31e5a214db49127c9df1c97aef2","c9ee668013fc4638876f96bb2509e1c9","178bcf7f8d1744c39a8a908771e4b66d","e2ecad26a512490cae1f4b1dc2578861","740736efbab34b5f9dee0a5bfe91c077","f11df1de6bfd4c5dbad8477792e16733","5045954242d842c9ab867c5697dfec4a","10609b7f781141238216fcf64ec06d93","e839f710ec2e4a89a6b355c6dbbc5478","c5e1505c2b8f4020a2151a0094462725","155b8ba31e4346f8acada343163f170e","1aa5748f4bf34d67bbc46d3fd045070a","7958e577bc094a41b615922d48469c36","5b26df9d3a8f440ebc7de04f63dfddb2","ff517a15bc7043ed8e0f1ce433f68e7d"]},"id":"lUM-al_UGI3d","executionInfo":{"status":"ok","timestamp":1669435535759,"user_tz":420,"elapsed":588,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"10df87a0-f31c-46d6-ae1b-2aad675cf2fc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b402fc1fdef4e4c86ee114e162f1162"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"740736efbab34b5f9dee0a5bfe91c077"}},"metadata":{}}]},{"cell_type":"code","source":["# Data collation for the task\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"],"metadata":{"id":"W1HnkBLmGVm3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_out_path = os.path.join(root_path, 'towemodel')"],"metadata":{"id":"G4CeLkPRL6vk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_list = ['O', 'B']\n","metric = load_metric(\"seqeval\")\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"],"metadata":{"id":"ZbGSSDMsVRSJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set training arguments\n","training_args = TrainingArguments(\n","    output_dir=model_out_path,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy='no',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_towedata[\"train\"],\n","    eval_dataset=tokenized_towedata[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"id":"7YGDScN8Evvg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669435555952,"user_tz":420,"elapsed":459,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"bcf1661a-5bc9-41f4-aa65-d7e1bc5031fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["# Fit the model\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":776},"id":"53EQ2218MW8G","executionInfo":{"status":"ok","timestamp":1669435653847,"user_tz":420,"elapsed":93708,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"4a9d29a7-e797-472d-a0d4-b4453eea3a07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, __index_level_0__, tags. If tokens, __index_level_0__, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 1631\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 408\n","  Number of trainable parameters = 108893186\n","You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='408' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [408/408 01:30, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.076202</td>\n","      <td>0.750000</td>\n","      <td>0.743243</td>\n","      <td>0.746606</td>\n","      <td>0.970289</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.065945</td>\n","      <td>0.773963</td>\n","      <td>0.812312</td>\n","      <td>0.792674</td>\n","      <td>0.974976</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.066177</td>\n","      <td>0.812596</td>\n","      <td>0.794294</td>\n","      <td>0.803341</td>\n","      <td>0.977098</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.072096</td>\n","      <td>0.817610</td>\n","      <td>0.780781</td>\n","      <td>0.798771</td>\n","      <td>0.976833</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, __index_level_0__, tags. If tokens, __index_level_0__, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 479\n","  Batch size = 16\n","The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, __index_level_0__, tags. If tokens, __index_level_0__, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 479\n","  Batch size = 16\n","The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, __index_level_0__, tags. If tokens, __index_level_0__, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 479\n","  Batch size = 16\n","The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, __index_level_0__, tags. If tokens, __index_level_0__, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 479\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=408, training_loss=0.06275356049631156, metrics={'train_runtime': 93.6761, 'train_samples_per_second': 69.644, 'train_steps_per_second': 4.355, 'total_flos': 203736449505564.0, 'train_loss': 0.06275356049631156, 'epoch': 4.0})"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["trainer.save_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRe1QUI5MfMy","executionInfo":{"status":"ok","timestamp":1669435693440,"user_tz":420,"elapsed":1994,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"5442986b-731c-4bdc-c80d-0e02d0057fcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/MyDrive/Knowledge/MSIT/IFT598 - NLP/Final Project/towemodel\n","Configuration saved in /content/drive/MyDrive/Knowledge/MSIT/IFT598 - NLP/Final Project/towemodel/config.json\n","Model weights saved in /content/drive/MyDrive/Knowledge/MSIT/IFT598 - NLP/Final Project/towemodel/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/Knowledge/MSIT/IFT598 - NLP/Final Project/towemodel/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/Knowledge/MSIT/IFT598 - NLP/Final Project/towemodel/special_tokens_map.json\n"]}]},{"cell_type":"code","source":["tr_predictions, tr_labels, _ = trainer.predict(tokenized_towedata[\"train\"])\n","predictions = np.argmax(tr_predictions, axis=2)\n","\n","# Remove ignored index (special tokens)\n","true_predictions = [\n","    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, tr_labels)\n","]\n","true_labels = [\n","    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, tr_labels)\n","]\n","\n","results = metric.compute(predictions=true_predictions, references=true_labels)\n","results"],"metadata":{"id":"LQXSbnrwUU81","colab":{"base_uri":"https://localhost:8080/","height":245},"executionInfo":{"status":"ok","timestamp":1669435708259,"user_tz":420,"elapsed":7977,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"4dde9960-6dcf-47b6-c01d-df0f4cc5b294"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, __index_level_0__, tags. If tokens, __index_level_0__, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 1631\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'_': {'precision': 0.9223892726533929,\n","  'recall': 0.9684300341296929,\n","  'f1': 0.9448491155046826,\n","  'number': 2344},\n"," 'overall_precision': 0.9223892726533929,\n"," 'overall_recall': 0.9684300341296929,\n"," 'overall_f1': 0.9448491155046826,\n"," 'overall_accuracy': 0.9940034395365677}"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["te_predictions, te_labels, _ = trainer.predict(tokenized_towedata[\"test\"])\n","predictions = np.argmax(te_predictions, axis=2)\n","\n","# Remove ignored index (special tokens)\n","true_predictions = [\n","    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, te_labels)\n","]\n","true_labels = [\n","    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, te_labels)\n","]\n","\n","results = metric.compute(predictions=true_predictions, references=true_labels)\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"M1uYvx_rXFED","executionInfo":{"status":"ok","timestamp":1669435716720,"user_tz":420,"elapsed":2641,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"71c115e1-a4b7-4fb4-d622-b99b24f65679"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, __index_level_0__, tags. If tokens, __index_level_0__, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 479\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'_': {'precision': 0.8176100628930818,\n","  'recall': 0.7807807807807807,\n","  'f1': 0.7987711213517665,\n","  'number': 666},\n"," 'overall_precision': 0.8176100628930818,\n"," 'overall_recall': 0.7807807807807807,\n"," 'overall_f1': 0.7987711213517665,\n"," 'overall_accuracy': 0.9768326111946237}"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["idx = 244\n","tks = tokenized_towedata[\"test\"][idx]['tokens']\n","preds = predictions[idx][:len(tks)+2][1:-1]\n","print('Labels: ', tokenized_towedata[\"test\"][idx]['labels'][1:-1])\n","print('Preds: ', preds)\n","print(tks)\n","aspect_terms = [tks[idx] for idx, i in enumerate(preds) if i==1]\n","aspect_terms"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TsCOPPjjZAUm","executionInfo":{"status":"ok","timestamp":1669435759159,"user_tz":420,"elapsed":237,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"b285b4a8-bf8c-447e-a540-37b0c576e5d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Labels:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Preds:  [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","['I', 'needed', 'a', 'laptop', 'with', 'big', 'storage', ',', 'a', 'nice', 'screen', 'and', 'fast', 'so', 'I', 'can', 'photoshop', 'without', 'any', 'problem', '.', 'The', 'aspect', 'identified', 'is', ':', 'storage']\n"]},{"output_type":"execute_result","data":{"text/plain":["['big']"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["sample_text = 'The restaurant has an incredible selection of beverages. The aspect identified is beverages'\n","# sample_text = 'The cab ride was bumpy but the driver was very friendly. The aspect identified is cab ride'\n","# sample_text = 'The movie was not that great bu the actor was really handsome. The aspect identified is movie.'\n","tokens = word_tokenize(sample_text)\n","dummy_tags = [1]*len(tokens)\n","dummy_labels = [1]*len(tokens)\n","temp_df = pd.DataFrame({'tokens':[tokens], 'tags':[dummy_tags], 'labels':[dummy_tags]})\n","\n","tokenized_df = Dataset.from_pandas(temp_df).map(tokenize_and_align_labels, batched=True)\n","\n","preds_, labels_, _ = trainer.predict(tokenized_df)\n","preds_ = np.argmax(preds_, axis=2)\n","\n","\n","idx = 0\n","tks_ = tokenized_df[idx]['tokens']\n","print('Tokens: ', tks_)\n","preds_id = preds_[idx][:len(tks_)+2][1:-1]\n","print('Labels: ', tokenized_df[idx]['labels'][1:-1])\n","print('Preds: ', preds_id)\n","aspect_terms_sample = [tks_[idx] for idx, i in enumerate(preds_id) if i==1]\n","aspect_terms_sample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["8030147aaada4cb688eddd7eadeaa352","7f031f9709c94ad3a3190c24a04b48de","d7b9c40e673e4ac99d8624066410b4fc","a772a4f338f7454a8f228d8641e2479f","dcbe36f672734b66ab7ecec68e30dd33","5d9236c631604726993957cacb5ecf51","aa027595e29746b0be444f164907c999","14dcff6c33474e0bb23b4def5aba4a67","6b5ac2cd8434478d9fa1f68169871aa7","ea304110634d4573976e11246352b6d0","2cdd82dfb3f7438194ddb78f37f299c7"]},"id":"apyT6CWMe25d","executionInfo":{"status":"ok","timestamp":1669435959556,"user_tz":420,"elapsed":251,"user":{"displayName":"Kevin Scaria","userId":"09596160905637401311"}},"outputId":"326b6739-950d-4ed6-de49-7f6eae10144d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8030147aaada4cb688eddd7eadeaa352"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 1\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokens:  ['The', 'restaurant', 'has', 'an', 'incredible', 'selection', 'of', 'beverages', '.', 'The', 'aspect', 'identified', 'is', 'beverages']\n","Labels:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","Preds:  [0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n"]},{"output_type":"execute_result","data":{"text/plain":["['incredible']"]},"metadata":{},"execution_count":59}]}]}